{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalization refers to your model's ability to adapt properly to new, previously unseen data, drawn from the same distribution as the one used to create the model.\n",
    "\n",
    "(Early stopping, Dropout, Cross-validation, L1 regularization, L2 regularization, ...)\n",
    "<br><br>\n",
    "### Overfitting\n",
    "\n",
    "Overfitting is \"the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably\".\n",
    "\n",
    "![overfitting](./overfitting.png)\n",
    "\n",
    "<div align=\"right\">\n",
    "https://en.wikipedia.org/wiki/Overfitting\n",
    "    <div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping\n",
    "\n",
    "Early stopping is a method to complete network training using a validation set prior to overfitting. \n",
    "\n",
    "\n",
    "![early_stopping](./early_stopping.png)\n",
    "\n",
    "Training error continues to decrease as learning proceeds and validation error begins to increase again. Dashed line points where we need to stop learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "In dropout method, each unit in the network, is chosen with probability p and training is only implemented with the selected units. The reason that the\n",
    "dropout algorithm is effective for a generalization is that it can be considered as a bagging ensemble algorithm. \n",
    "\n",
    "![dropout](./dropout.png)\n",
    "\n",
    "<div align=\"right\">\n",
    "http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf\n",
    "    <div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "In machine learning, the raw data set is commonly divided into three parts: training set, validation set and test set to avoid overfitting. However, it may be problematic if the total amounts of data being possessed are not sufficient. It is due to the performance of model can vary greatly depending on which data is actually being contained in each of training set, validation set and test set. To improve this issue, the method of k-fold cross validation is widely used, which is one of the types of resampling methods.\n",
    "\n",
    "![cross_validation](./cv.png)\n",
    "\n",
    "<div align=\"right\">\n",
    "https://www.kaggle.com/dansbecker/cross-validation\n",
    "    <div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential\n",
    "# Dropout\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "from IPython.display import SVG\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style()\n",
    "\n",
    "# train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load mnist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist data and split between train and test sets\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train\n",
    "y_train = y_train\n",
    "x_test = x_test\n",
    "y_test = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of mnist data\n",
    "\n",
    "print(\"Shape of x_train:\",x_train.shape)\n",
    "print(\"Shape of y_train:\",y_train.shape)\n",
    "print(\"Shape of x_test:\",x_test.shape)\n",
    "print(\"Shape of y_test:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample images and correspoding label\n",
    "\n",
    "def plot_images(number_of_samples, data_set = x_train):\n",
    "    \n",
    "    if np.array_equal(data_set, x_train):\n",
    "        label = y_train\n",
    "    else:\n",
    "        label = y_test\n",
    "        \n",
    "    number_of_samples = number_of_samples//8*8 \n",
    "    fig, ax = plt.subplots(number_of_samples//8, 8, figsize=(16,5), constrained_layout = True)\n",
    "    num = np.random.choice(len(data_set), number_of_samples, replace=False)\n",
    "    \n",
    "    for i,j in enumerate(num):\n",
    "        ax[i//8, i%8].imshow(data_set[j], cmap='gray')\n",
    "        ax[i//8, i%8].axis('off')\n",
    "        ax[i//8, i%8].set_title(f\"label: {label[j]}\")\n",
    "    plt.show()    \n",
    "    \n",
    "plot_images(16, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot label distribution of training set\n",
    "\n",
    "plt.title('Label distribution')\n",
    "plt.bar(range(10), np.bincount(y_train))\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(range(10))\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot label distributions of training set and validation set\n",
    "fig, ax = plt.subplots(1,2, figsize=(16,5), constrained_layout = True)\n",
    "\n",
    "ax[0].bar(range(10), np.bincount(y_train))\n",
    "ax[0].set_title('Label distribution')\n",
    "ax[0].set_xlabel('Label')\n",
    "ax[0].set_ylabel('Count')\n",
    "ax[0].set_xticks(range(10))\n",
    "ax[0].grid(False)\n",
    "\n",
    "ax[1].bar(range(10), np.bincount(y_valid))\n",
    "ax[1].set_title('Label distribution')\n",
    "ax[1].set_xlabel('Label')\n",
    "ax[1].set_ylabel('Count')\n",
    "ax[1].set_xticks(range(10))\n",
    "ax[1].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale the image data \n",
    "x_train = x_train.astype('float32')\n",
    "x_valid = x_valid.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_valid /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "# y_train = keras.utils.to_categorical(y_train, 10)\n",
    "# y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "#  reshape\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], -1)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training \n",
    "train_model = model.fit(x_train, y_train, epochs=20, verbose=2, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "def plot_result(train_model):\n",
    "    hist = train_model.history\n",
    "    acc = hist['acc']\n",
    "    val_acc = hist['val_acc']\n",
    "    loss = hist['loss']\n",
    "    val_loss = hist['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "    fig, ax = plt.subplots(1,2, figsize=(14,6))\n",
    "    \n",
    "    ax[0].plot(epochs, acc, 'g', label='Training accuracy')\n",
    "    ax[0].plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "    ax[0].set_title('Training and validation accuracy')\n",
    "    ax[0].legend(loc=1)\n",
    "    ax[1].plot(epochs, loss, 'g', label='Training loss')\n",
    "    ax[1].plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    ax[1].set_title('Training and validation loss')\n",
    "    ax[1].legend(loc=1)\n",
    "    plt.show()\n",
    "    \n",
    "plot_result(train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "prediction = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', prediction[0])\n",
    "print('Test accuracy:', prediction[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(model, to_file='model.png', show_shapes=True, rankdir='TB')\n",
    "\n",
    "# # Arguments\n",
    "# #         model: A Keras model instance\n",
    "# #         to_file: File name of the plot image.\n",
    "# #         show_shapes: whether to display shape information.\n",
    "# #         show_layer_names: whether to display layer names.\n",
    "# #         rankdir: `rankdir` argument passed to PyDot,\n",
    "# #             a string specifying the format of the plot:\n",
    "# #             'TB' creates a vertical plot;\n",
    "# #             'LR' creates a horizontal plot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
